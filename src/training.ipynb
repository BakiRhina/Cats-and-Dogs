{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries (torch, matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Users/Ato/Documents/Programming/Python/catdog/src/datasets\"\n",
    "train_path = PATH + \"/train\"\n",
    "test_path = PATH + \"/test1/test1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entries and number of samples of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(train_path)))\n",
    "print(len(os.listdir(test_path)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Taking a look at the filenames, it is possible extracting the name and label with ease with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(train_path)\n",
    "labels = [filename.split('.')[0] for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {'filename': filenames, 'label': labels}\n",
    "df = pd.DataFrame(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.0.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.1.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.10.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.100.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1000.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename label\n",
       "0     cat.0.jpg   cat\n",
       "1     cat.1.jpg   cat\n",
       "2    cat.10.jpg   cat\n",
       "3   cat.100.jpg   cat\n",
       "4  cat.1000.jpg   cat"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>cat.0.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  label\n",
       "count       25000  25000\n",
       "unique      25000      2\n",
       "top     cat.0.jpg    cat\n",
       "freq            1  12500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar_labels = df['label'].value_counts().index\n",
    "counts = df['label'].value_counts().values\n",
    "bar_colors = ['tab:red', 'tab:blue']\n",
    "\n",
    "ax.bar(bar_labels, counts, color=bar_colors)\n",
    "ax.legend(title=\"Data balance check\")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is balanced! Let's continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizing dimensions, shapes, sizes,...\n",
    "\n",
    "- Take a smaller sample but big enough to contain useful information. sample = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000\n",
    "sample_images = df['filename'].sample(sample_size).to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = []\n",
    "height = []\n",
    "channels = [] # channels\n",
    "\n",
    "for filename in sample_images:\n",
    "  image = cv2.imread(os.path.join(train_path, filename), 1)\n",
    "  width.append(image.shape[1])\n",
    "  height.append(image.shape[0])\n",
    "  channels.append(image.shape[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>374</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>374</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>243</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   width  height  channels\n",
       "0    500     374         3\n",
       "1    500     374         3\n",
       "2    374     500         3\n",
       "3    386     500         3\n",
       "4    200     243         3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dimensions = pd.DataFrame({\n",
    "  'width':width,\n",
    "  'height':height,  \n",
    "  'channels':channels\n",
    "})\n",
    "\n",
    "sample_dimensions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dimensions['aspect ratio'] = sample_dimensions['width']/sample_dimensions['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>channels</th>\n",
       "      <th>aspect ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>374</td>\n",
       "      <td>3</td>\n",
       "      <td>1.336898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>374</td>\n",
       "      <td>3</td>\n",
       "      <td>1.336898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>243</td>\n",
       "      <td>3</td>\n",
       "      <td>0.823045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   width  height  channels  aspect ratio\n",
       "0    500     374         3      1.336898\n",
       "1    500     374         3      1.336898\n",
       "2    374     500         3      0.748000\n",
       "3    386     500         3      0.772000\n",
       "4    200     243         3      0.823045"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dimensions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>channels</th>\n",
       "      <th>aspect ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>403.047200</td>\n",
       "      <td>361.025400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.151117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>108.838622</td>\n",
       "      <td>96.137044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>321.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.919830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>442.000000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.256281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>499.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.336898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.840909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             width       height  channels  aspect ratio\n",
       "count  5000.000000  5000.000000    5000.0   5000.000000\n",
       "mean    403.047200   361.025400       3.0      1.151117\n",
       "std     108.838622    96.137044       0.0      0.288460\n",
       "min      50.000000    32.000000       3.0      0.350000\n",
       "25%     321.000000   303.000000       3.0      0.919830\n",
       "50%     442.000000   374.000000       3.0      1.256281\n",
       "75%     499.000000   421.000000       3.0      1.336898\n",
       "max     500.000000   500.000000       3.0      2.840909"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dimensions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the percentile 95th, so we know what value the majority of the features have.\n",
    "\n",
    "It seems that most of the values are below 500 in width and height and hte aspect ratio is about 1.5, which means that the width is usually 1.5 times bigger than the height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500.0, 500.0, 1.5105740181268883)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(width, 0.95), np.quantile(height, 0.95), np.quantile(sample_dimensions['aspect ratio'], 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trying with different methods to obtain the quantile. All produce the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500.0, 500, 500, 500.0, 500.0, 500.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(width, 0.95, method='hazen'), np.quantile(width, 0.95, method='closest_observation'), np.quantile(width, 0.95, method='higher'), np.quantile(width, 0.95, method='averaged_inverted_cdf'), np.quantile(width, 0.95, method='linear'), np.quantile(width, 0.95, method='median_unbiased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesandnames = sample_dimensions\n",
    "#print(sample_images[:10])\n",
    "samplesandnames['filename'] = sample_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum goal is to preserve quality. From the quantiles, it has been deducted that most of the width and height values fall below 500 while the aspect ratio (AR) is 1.5 in the majority of cases. More data is lost when oversampling the images than when undersampling them, so only the smallest widths and heghts will be removed. Since most of the aspect ratio values fall below 1.5, all AR values between 0.7 and 2 will be removed as well.\n",
    "\n",
    "- Width > 150\n",
    "- Height > 100\n",
    "- 0.7 > Aspect Ratio > 2\n",
    "\n",
    "These values can be tuned to obtain different results.\n",
    "**The smaller the range, the lesser data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_samples = samplesandnames[\n",
    "  (samplesandnames['width'] >= 150) &\n",
    "  (samplesandnames['height'] >= 100) &\n",
    "  (samplesandnames['aspect ratio'] >= 0.7) &\n",
    "  (samplesandnames['aspect ratio'] <= 2)\n",
    "]\n",
    "\n",
    "processed_samples = processed_samples.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>channels</th>\n",
       "      <th>aspect ratio</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>374</td>\n",
       "      <td>3</td>\n",
       "      <td>1.336898</td>\n",
       "      <td>cat.943.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>374</td>\n",
       "      <td>3</td>\n",
       "      <td>1.336898</td>\n",
       "      <td>dog.6695.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>cat.1616.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>dog.1224.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>243</td>\n",
       "      <td>3</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>dog.3890.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   width  height  channels  aspect ratio      filename\n",
       "0    500     374         3      1.336898   cat.943.jpg\n",
       "1    500     374         3      1.336898  dog.6695.jpg\n",
       "2    374     500         3      0.748000  cat.1616.jpg\n",
       "3    386     500         3      0.772000  dog.1224.jpg\n",
       "4    200     243         3      0.823045  dog.3890.jpg"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the **outliers** have been deleted, the amount of data reduced needs to be checked out. Looking at the outcome, most of the images are not considered outliers, although almost 10% of the sample data has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>channels</th>\n",
       "      <th>aspect ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4560.000000</td>\n",
       "      <td>4560.000000</td>\n",
       "      <td>4560.0</td>\n",
       "      <td>4560.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>417.577412</td>\n",
       "      <td>360.857018</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.185791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>98.409689</td>\n",
       "      <td>88.651951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.987970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>473.000000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.322487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>499.000000</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.336898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             width       height  channels  aspect ratio\n",
       "count  4560.000000  4560.000000    4560.0   4560.000000\n",
       "mean    417.577412   360.857018       3.0      1.185791\n",
       "std      98.409689    88.651951       0.0      0.248915\n",
       "min     150.000000   101.000000       3.0      0.700000\n",
       "25%     350.000000   312.000000       3.0      0.987970\n",
       "50%     473.000000   374.000000       3.0      1.322487\n",
       "75%     499.000000   403.000000       3.0      1.336898\n",
       "max     500.000000   500.000000       3.0      2.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_samples.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Preprocessing\n",
    "\n",
    "- The same sample preprocessing is now applied to all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       filename label\n",
       " 0     cat.0.jpg   cat\n",
       " 1     cat.1.jpg   cat\n",
       " 2    cat.10.jpg   cat\n",
       " 3   cat.100.jpg   cat\n",
       " 4  cat.1000.jpg   cat,\n",
       " 25000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(), len(df.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = []\n",
    "height = []\n",
    "\n",
    "for filename in df['filename']:\n",
    "  image = cv2.imread(os.path.join(train_path, filename))  \n",
    "\n",
    "  width.append(image.shape[1])\n",
    "  height.append(image.shape[0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers Note\n",
    "\n",
    "- Width > 100\n",
    "- Height > 150\n",
    "- 0.7 > Aspect Ratio > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.DataFrame({'filename': df['filename'], 'width': width, 'height': height, 'label': df['label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['aspect ratio'] = full_data['width'] / full_data['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data[\n",
    "  (full_data['width'] >= 100) &\n",
    "  (full_data['height'] >= 150) &\n",
    "  (full_data['aspect ratio'] >= 0.7) &\n",
    "  (full_data['aspect ratio'] <= 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking if the data is still balanced after preprocessing. It is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data['label'].value_counts().sort_index().plot(kind='bar', color=['blue', 'red'])\n",
    "\n",
    "plt.title('Filtered dataset Balance')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle\n",
    "\n",
    "Before splitting into training and validation it is necessary to shuffle the data to avoid overfitting due to predetermined orders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>aspect ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22556.00000</td>\n",
       "      <td>22556.000000</td>\n",
       "      <td>22556.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>421.18709</td>\n",
       "      <td>363.225173</td>\n",
       "      <td>1.185901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.20635</td>\n",
       "      <td>86.098052</td>\n",
       "      <td>0.247402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>109.00000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>350.75000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>0.989432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>479.00000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>1.325231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>499.00000</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>1.336898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1050.00000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             width        height  aspect ratio\n",
       "count  22556.00000  22556.000000  22556.000000\n",
       "mean     421.18709    363.225173      1.185901\n",
       "std       96.20635     86.098052      0.247402\n",
       "min      109.00000    150.000000      0.700000\n",
       "25%      350.75000    314.000000      0.989432\n",
       "50%      479.00000    374.000000      1.325231\n",
       "75%      499.00000    405.000000      1.336898\n",
       "max     1050.00000    768.000000      2.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frac = 1 -> all data\n",
    "# drop=True --> removes old index and creates a new one for the new sorted dataframe\n",
    "# If no index is desired:\n",
    "#   1. full_data.sample(frac=1).reset_index(drop=True, inplace=True) -> with the original dataframe (full_data)\n",
    "#   2. shuffled_data.to_csv('shuffled_data.csv', index=False) -> with a new variable\n",
    "shuffled_data = full_data.sample(frac=1).reset_index(drop=True) \n",
    "shuffled_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation - Training set split\n",
    "\n",
    "Since the features width, height and aspect ratio were created only for preprocessing purposes it is safe to remove them. Furthermore, it is a good practice to create a checkpoint of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "      <th>aspect ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog.8559.jpg</td>\n",
       "      <td>500</td>\n",
       "      <td>374</td>\n",
       "      <td>dog</td>\n",
       "      <td>1.336898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog.3995.jpg</td>\n",
       "      <td>461</td>\n",
       "      <td>499</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.923848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog.6898.jpg</td>\n",
       "      <td>386</td>\n",
       "      <td>500</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog.9949.jpg</td>\n",
       "      <td>298</td>\n",
       "      <td>377</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.790451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1770.jpg</td>\n",
       "      <td>500</td>\n",
       "      <td>415</td>\n",
       "      <td>cat</td>\n",
       "      <td>1.204819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename  width  height label  aspect ratio\n",
       "0  dog.8559.jpg    500     374   dog      1.336898\n",
       "1  dog.3995.jpg    461     499   dog      0.923848\n",
       "2  dog.6898.jpg    386     500   dog      0.772000\n",
       "3  dog.9949.jpg    298     377   dog      0.790451\n",
       "4  cat.1770.jpg    500     415   cat      1.204819"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkpoint\n",
    "\n",
    "'''\n",
    "Internally, in python, copy() method uses a pointer to the original data, which\n",
    "means that changes to the new object will affect the old. To overcome this, set deep=True.\n",
    "For non-pandas objects, use copy.deepcopy(<object>)\n",
    "'''\n",
    "\n",
    "data = shuffled_data.copy(deep=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog.8559.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog.3995.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog.6898.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog.9949.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1770.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename label\n",
       "0  dog.8559.jpg   dog\n",
       "1  dog.3995.jpg   dog\n",
       "2  dog.6898.jpg   dog\n",
       "3  dog.9949.jpg   dog\n",
       "4  cat.1770.jpg   cat"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unwwanted features\n",
    "\n",
    "data = data.drop(['width', 'height', 'aspect ratio'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set integers for labels instead of strings using a simple lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog.8559.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog.3995.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog.6898.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog.9949.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1770.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename  label\n",
       "0  dog.8559.jpg      0\n",
       "1  dog.3995.jpg      0\n",
       "2  dog.6898.jpg      0\n",
       "3  dog.9949.jpg      0\n",
       "4  cat.1770.jpg      1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"] = data[\"label\"].apply(lambda x: 0 if x == 'dog' else 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22556"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_length = len(data.index)\n",
    "data_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, there are still more than 22000 images. A ratio of 80% (training) 20% (validation) for this amoount of data seems correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounded 18045\n",
      "int 18044\n",
      "float 18044.8\n",
      "Error round: 0.2000000000007276\n",
      "Error int: 0.7999999999992724\n"
     ]
    }
   ],
   "source": [
    "train_len_round = round(len(data.index)*0.8)\n",
    "train_len_int = int(len(data.index)*0.8)\n",
    "train_len_float = len(data.index)*0.8\n",
    "\n",
    "print(f'Rounded {train_len_round}')\n",
    "print(f'int {train_len_int}')\n",
    "print(f'float {train_len_float}')\n",
    "\n",
    "print(f'Error round: {abs(train_len_float-train_len_round)}')\n",
    "print(f'Error int: {abs(train_len_float-train_len_int)}')\n",
    "\n",
    "# More precision using round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18045, 2), (4511, 2))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = data.iloc[:train_len_round,:]\n",
    "val_df = data.iloc[train_len_round:, :]\n",
    "\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8000088668203582, 0.1999911331796418)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]/data_length, val_df.shape[0]/data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolut errors: [8.86682035816655e-06, 8.86682035822206e-06]\n"
     ]
    }
   ],
   "source": [
    "abs_err_train = abs(0.8-train_df.shape[0]/data_length)\n",
    "abs_err_val = abs(0.2-val_df.shape[0]/data_length)\n",
    "\n",
    "errors = [abs_err_train, abs_err_val]\n",
    "\n",
    "print(f'Absolut errors: {errors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting completed with a small error (Ea ~ 8.87e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Pytorch\n",
    "\n",
    "The dataset will be fed to a convolutional neural network model. This model is defined below and its main file can be found in `/modules/cnn.py`. For the moment, it has 2 convolutional layers, 2 pooling layers and 3 fully connected layers. The input depends on the size of the kernels and the image resizing.\n",
    "To calculate the input-size in the neural networks, refer to https://github.com/BakiRhina/Cats-and-Dogs#important-note-on-fc1-shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(3,6,5) # (N_in_channels, N_out_channels, kernel_size)\n",
    "    self.conv2 = nn.Conv2d(6,16,5)\n",
    "    self.pool = nn.MaxPool2d(2,2)\n",
    "    self.fc1 = nn.Linear(16*93*61, 256)\n",
    "    self.fc2 = nn.Linear(256, 120)\n",
    "    self.fc3 = nn.Linear(120, 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = torch.flatten(x, 1) \n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks, specially if fed with big datasets containing images, consume lots of resources. That is why using cudas gpu is a good option if available, to reduce time consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Select GPU if available (cuda toolkit <= 11.8 for pytorch)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "# Enables benchmark mode in cudnn to find the best algorithm to use for your hardware.\n",
    "#more info --> https://pytorch.org/docs/stable/backends.html#torch.backends.mps.is_built\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, looking at the 95% percentile, the aspect ratio is around 1.5. Therefore, some combinations to try out, without loosing much resolution and information would be: (384,256,3);(256,256,3);(128,128,3);..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to try different sizes\n",
    "\n",
    "input_shape = (384,256)\n",
    "#input_shape = (256,256)\n",
    "#input_shape = (128,128)\n",
    "\n",
    "df_transform = transforms.Compose([\n",
    "  transforms.Resize(input_shape),\n",
    "  transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.506511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  18045.000000\n",
       "mean       0.506511\n",
       "std        0.499971\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why the custom dataset? It is possible to use the class Dataset to create Dataset-like objects and then pass it to the DataLoader. This class is optimized to be less memory consuming (processes data in separate cores in real time and feed it immediately to the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, dataframe, root_dir , transform=None):\n",
    "    self.dataframe = dataframe\n",
    "    self.root_dir = root_dir\n",
    "    self.transform = transform\n",
    "  \n",
    "  #DataLoader will automatically use these methods (__len__() and __getitem__())\n",
    "  #To calculate the amount of iterations with the selected batch\n",
    "  def __len__(self):\n",
    "    return len(self.dataframe)\n",
    "\n",
    "  #To select the samples of data form the dataframe\n",
    "  def __getitem__(self, idx):\n",
    "    img_filepath = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
    "    image = Image.open(img_filepath).convert(\"RGB\")\n",
    "    label = self.dataframe.iloc[idx, 1]\n",
    "\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    return image, label\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instance of training and validating sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(train_df, train_path, transform=df_transform)\n",
    "val_set = CustomDataset(val_df, train_path, transform=df_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Torch loader with batch size of 16/32, and shuffled again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "momentum = 0.9\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "[1,    50] loss: 0.014\n",
      "[1,   100] loss: 0.013\n",
      "[1,   150] loss: 0.013\n",
      "[1,   200] loss: 0.014\n",
      "[1,   250] loss: 0.014\n",
      "[1,   300] loss: 0.014\n",
      "[1,   350] loss: 0.014\n",
      "[1,   400] loss: 0.014\n",
      "[1,   450] loss: 0.014\n",
      "[1,   500] loss: 0.014\n",
      "[1,   550] loss: 0.014\n",
      "Epoch 1\n",
      "[2,    50] loss: 0.014\n",
      "[2,   100] loss: 0.014\n",
      "[2,   150] loss: 0.013\n",
      "[2,   200] loss: 0.014\n",
      "[2,   250] loss: 0.014\n",
      "[2,   300] loss: 0.015\n",
      "[2,   350] loss: 0.014\n",
      "[2,   400] loss: 0.015\n",
      "[2,   450] loss: 0.015\n",
      "[2,   500] loss: 0.014\n",
      "[2,   550] loss: 0.014\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = opt.SGD(cnn.parameters(), lr, momentum)\n",
    "loss_values = []\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "  print(f'Epoch {epoch}')\n",
    "  running_loss = 0.0\n",
    "  for i, data in enumerate(train_loader, 0):\n",
    "    imgs, label = data\n",
    "    imgs, label = imgs.to(device), label.to(device)\n",
    "\n",
    "    # Forward pass + Backward pass + Gradient optimization\n",
    "\n",
    "    output = cnn(imgs)\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    if i % 50 == 49:\n",
    "      running_loss += loss.item()\n",
    "      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "      loss_values.append(running_loss)\n",
    "      running_loss = 0.0\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FC1 input calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 384, 256])\n",
      "torch.Size([32, 6, 380, 252])\n",
      "torch.Size([32, 6, 190, 126])\n",
      "torch.Size([32, 16, 186, 122])\n",
      "torch.Size([32, 16, 93, 61])\n",
      "torch.Size([32, 90768])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(3,6,5)\n",
    "pool = nn.MaxPool2d(2,2)\n",
    "conv2 = nn.Conv2d(6,16,5)\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "x = conv1(images)\n",
    "print(x.shape)\n",
    "x = pool(x)\n",
    "print(x.shape)\n",
    "x = conv2(x)\n",
    "print(x.shape)\n",
    "x = pool(x)\n",
    "print(x.shape)\n",
    "x = torch.flatten(x, 1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
